{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import permutations\n",
    "\n",
    "from envs.vases_grid import VasesGrid, VasesEnvState, print_state, str_to_state, state_to_str\n",
    "from envs.utils import unique_perm, zeros_with_ones, printoptions\n",
    "from envs.vases_spec import VasesEnvState2x3_2v2d, VasesEnvSpec2x3_2v2d, VasesEnvState3x3, VasesEnvSpec3x3, VasesEnvState2x3Broken, VasesEnvSpec2x3Broken\n",
    "\n",
    "from value_iter_and_policy import vi_boltzmann, vi_boltzmann_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_D_last_step_discrete(mdp, policy, p_0, T, verbose=False):\n",
    "    '''\n",
    "    computes the last-step occupancy measure \n",
    "    '''\n",
    "    D_prev = p_0 \n",
    "    \n",
    "    t = 0\n",
    "    for t in range(T):\n",
    "        \n",
    "        # for T-step OM we'd do D=np.copy(P_0). However, we want the last step one, so:\n",
    "        D = np.zeros_like(p_0)\n",
    "        \n",
    "        for s in range(mdp.nS):\n",
    "            for a in range(mdp.nA):\n",
    "                # due to env being deterministic, sprime=self.P[s][a][1] and p_sprime=1\n",
    "                D[mdp.P[s][a][1]] += D_prev[s] * policy[s, a] \n",
    "                    \n",
    "        D_prev = np.copy(D)\n",
    "        if verbose is True: print(D)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OM_method(mdp, current_state, p_0, horizon, temperature=1, epochs=1, learning_rate=0.2, r_vec=None):\n",
    "    '''\n",
    "    Modified MaxCausalEnt that maximizes last step occupancy measure for the current state\n",
    "    '''\n",
    "    \n",
    "    if r_vec is None:\n",
    "        r_vec = .01*np.random.randn(mdp.f_matrix.shape[1])\n",
    "        print('Initial reward vector: {}'.format(r_vec))\n",
    "        \n",
    "    for i in range(epochs):\n",
    "        \n",
    "            # Compute the Boltzmann rational policy \\pi_{s,a} = \\exp(Q_{s,a} - V_s) \n",
    "            V, Q, policy = vi_boltzmann_deterministic(mdp, 1, mdp.f_matrix @ r_vec, horizon, temperature) \n",
    "            \n",
    "            D = compute_D_last_step_discrete(mdp, policy, p_0, horizon)   \n",
    "            dL_dr_vec = -(current_state - D) @ mdp.f_matrix\n",
    "\n",
    "            # Gradient descent; gradiend may not be the actual gradient -- have to check the math,\n",
    "            # bit this should do the matching correctly\n",
    "            r_vec = r_vec - learning_rate * dL_dr_vec\n",
    "            \n",
    "            if i%20==0:\n",
    "                with printoptions(precision=4, suppress=True):\n",
    "                    print('Epoch {}; Reward vector: {}'.format(i, r_vec))\n",
    "                # print('Policy: {}'.format(policy))\n",
    "                # print('Last-step D: {} \\n'.format(D))\n",
    "\n",
    "    return r_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_grid(env,\n",
    "                 horizon=22, #number of timesteps we assume the expert has been acting previously\n",
    "                 temperature_irl=1,\n",
    "                 learning_rate=.1,\n",
    "                 epochs = 200):\n",
    "\n",
    "    print('Number of states: ', env.deterministic_T.shape[0])\n",
    "    print('Initial state:')\n",
    "    print_state(env.init_state)\n",
    "\n",
    "    p_0=np.zeros(env.nS)\n",
    "    p_0[env.state_num[state_to_str(env.init_state)]] = 1\n",
    "    \n",
    "    current_state = np.copy(p_0)\n",
    "    \n",
    "    r_vec = OM_method(env, current_state, p_0, horizon, temperature_irl, epochs, learning_rate)\n",
    "    with printoptions(precision=4, suppress=True):\n",
    "        print(); print('Final reward vector: ', r_vec)\n",
    "    return r_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward RL with a given reward\n",
    "def forward_rl(env, r, h=40, temp=.1, steps_printed=15):\n",
    "    V, Q, policy = vi_boltzmann_deterministic(env, 1, env.f_matrix @ r, h, temp) \n",
    "\n",
    "    env.reset()\n",
    "    print_state(env.s); print()\n",
    "    for i in range(steps_printed):\n",
    "        a = np.random.choice(5,p=policy[env.state_num[state_to_str(env.s)],:])\n",
    "        env.step(a)\n",
    "        print_state(env.s)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states:  1692\n",
      "Initial state:\n",
      "│\u001b[0;35;85m█\u001b[0m\u001b[0;32;85m█\u001b[0m│  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m↑\u001b[0m │  │  │\n",
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969  0.00865408 -0.02301539]\n",
      "Epoch 0; Reward vector: [-0.0007  0.0072 -0.0053 -0.0109  0.0364 -0.0214]\n",
      "Epoch 20; Reward vector: [-0.0348  0.111  -0.0053 -0.0116  0.1262 -0.0133]\n",
      "Epoch 40; Reward vector: [-0.0397  0.1519 -0.0053 -0.012   0.1562 -0.0087]\n",
      "Epoch 60; Reward vector: [-0.0418  0.1799 -0.0053 -0.0123  0.1774 -0.005 ]\n",
      "Epoch 80; Reward vector: [-0.043   0.2019 -0.0053 -0.0125  0.1946 -0.002 ]\n",
      "Epoch 100; Reward vector: [-0.0437  0.2206 -0.0053 -0.0128  0.2094  0.0006]\n",
      "Epoch 120; Reward vector: [-0.0442  0.237  -0.0053 -0.0129  0.2227  0.003 ]\n",
      "Epoch 140; Reward vector: [-0.0446  0.2517 -0.0053 -0.0131  0.235   0.0051]\n",
      "Epoch 160; Reward vector: [-0.0448  0.2652 -0.0053 -0.0132  0.2463  0.0069]\n",
      "Epoch 180; Reward vector: [-0.045   0.2777 -0.0053 -0.0134  0.257   0.0087]\n",
      "\n",
      "Final reward vector:  [-0.0451  0.2889 -0.0053 -0.0135  0.2666  0.0102]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "env2x3_2v2d = VasesGrid(VasesEnvSpec2x3_2v2d(), VasesEnvState2x3_2v2d())\n",
    "r_learned = experiment_grid(env2x3_2v2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│\u001b[0;35;85m█\u001b[0m\u001b[0;32;85m█\u001b[0m│  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m↑\u001b[0m │  │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[1;42;42m↑\u001b[0m │  │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;42;42m→\u001b[0m │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[0m→\u001b[0m │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m→\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m↑\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[1;42;42m↑\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;42;42m←\u001b[0m │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│ \u001b[91m█\u001b[0m│\u001b[0m←\u001b[0m │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m←\u001b[0m\u001b[91m█\u001b[0m│  │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m↑\u001b[0m\u001b[91m█\u001b[0m│  │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│  │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[1;45;45m↑\u001b[0m\u001b[91m█\u001b[0m│  │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│  │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│ \u001b[91m█\u001b[0m│\u001b[1;45;45m→\u001b[0m │ \u001b[91m█\u001b[0m│\n",
      "\n",
      "│  │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│ \u001b[91m█\u001b[0m│  │\u001b[1;45;45m→\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n",
      "│  │  │  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│ \u001b[91m█\u001b[0m│  │\u001b[1;45;45m↑\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│ \u001b[91m█\u001b[0m│  │\u001b[0m↑\u001b[0m\u001b[91m█\u001b[0m│\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use R_rl that rewards the agent for tablecloths on tables; \n",
    "# both vases get broken\n",
    "r_rl = np.array([0, 0, 1, 0, 0, 0])\n",
    "forward_rl(env2x3_2v2d, r_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│\u001b[0;35;85m█\u001b[0m\u001b[0;32;85m█\u001b[0m│  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m↑\u001b[0m │  │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[1;42;42m↑\u001b[0m │  │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;42;42m→\u001b[0m │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │  │ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;42;42m↑\u001b[0m │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[0m↑\u001b[0m │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m←\u001b[0m │  │  │\n",
      "\n",
      "│\u001b[0;35;85m█\u001b[0m │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[0m↑\u001b[0m │  │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│\u001b[1;45;45m↑\u001b[0m │  │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;45;45m→\u001b[0m │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │\u001b[0m→\u001b[0m │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │  │\u001b[0m→\u001b[0m │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │  │\u001b[0m↑\u001b[0m │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │  │\u001b[1;42;42m↑\u001b[0m │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │\u001b[1;42;42m←\u001b[0m │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[1;42;42m←\u001b[0m │  │  │\n",
      "\n",
      "│  │ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[1;42;42m↑\u001b[0m │  │  │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0m↑\u001b[0m │  │  │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │\u001b[0;35;85m█\u001b[0m │\n",
      "│  │\u001b[0m→\u001b[0m │  │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[1;45;45m→\u001b[0m │  │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[1;45;45m→\u001b[0m │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│  │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[1;45;45m↑\u001b[0m │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m↑\u001b[0m │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │\u001b[0m←\u001b[0m │  │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m→\u001b[0m │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m→\u001b[0m │\n",
      "\n",
      "│ \u001b[0;32;85m█\u001b[0m│ \u001b[0;32;85m█\u001b[0m│\u001b[0;35;85m█\u001b[0m │\n",
      "│\u001b[0;33;85m█\u001b[0m │\u001b[0;33;85m█\u001b[0m │\u001b[93m█\u001b[0m │\n",
      "│──│──│──│\n",
      "│  │  │  │\n",
      "│  │  │\u001b[0m↑\u001b[0m │\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine the learned R_h + R* with a reward function R_rl that rewards the \n",
    "# agent for tablecloths on tables.\n",
    "# No vases broken!\n",
    "forward_rl(env2x3_2v2d, r_rl + r_learned, steps_printed=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.random.seed(1)\n",
    "#env2x3_broken = VasesGrid(VasesEnvSpec2x3Broken(), VasesEnvState2x3Broken())\n",
    "#experiment_grid(env2x3_broken)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
