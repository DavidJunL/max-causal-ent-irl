{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import permutations\n",
    "\n",
    "from envs.vases_grid import VasesGrid, VasesEnvState, print_state, str_to_state, state_to_str\n",
    "from envs.utils import unique_perm, zeros_with_ones\n",
    "from envs.vases_spec import VasesEnvState2x3, VasesEnvSpec2x3, VasesEnvState3x3, VasesEnvSpec3x3, VasesEnvState2x3Broken, VasesEnvSpec2x3Broken\n",
    "\n",
    "from value_iter_and_policy import vi_boltzmann, vi_boltzmann_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_D_last_step_discrete(mdp, policy, p_0, T, verbose=False):\n",
    "    '''\n",
    "    computes the last-step occupancy measure \n",
    "    '''\n",
    "    D_prev = p_0 \n",
    "    \n",
    "    t = 0\n",
    "    for t in range(T):\n",
    "        \n",
    "        # for T-step OM we'd do D=np.copy(P_0). However, we want the last step one, so:\n",
    "        D = np.zeros_like(p_0)\n",
    "        \n",
    "        for s in range(mdp.nS):\n",
    "            for a in range(mdp.nA):\n",
    "                # due to env being deterministic, sprime=self.P[s][a][1] and p_sprime=1\n",
    "                D[mdp.P[s][a][1]] += D_prev[s] * policy[s, a] \n",
    "                    \n",
    "        D_prev = np.copy(D)\n",
    "        if verbose is True: print(D)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OM_method(mdp, current_state, p_0, horizon, temperature=1, epochs=1, learning_rate=0.2, r_vec=None):\n",
    "    '''\n",
    "    Modified MaxCausalEnt that maximizes last step occupancy measure for the current state\n",
    "    '''\n",
    "    \n",
    "    if r_vec is None:\n",
    "        r_vec = .01*np.random.randn(mdp.feature_matrix.shape[1])\n",
    "        print('Initial reward vector: {}'.format(r_vec))\n",
    "        \n",
    "    for i in range(epochs):\n",
    "        \n",
    "            # Compute the Boltzmann rational policy \\pi_{s,a} = \\exp(Q_{s,a} - V_s) \n",
    "            V, Q, policy = vi_boltzmann_deterministic(mdp, 1, mdp.feature_matrix @ r_vec, horizon, temperature) \n",
    "            \n",
    "            D = compute_D_last_step_discrete(mdp, policy, p_0, horizon)   \n",
    "            dL_dr_vec = -(current_state - D) @ mdp.feature_matrix\n",
    "\n",
    "            # Gradient descent; gradiend may not be the actual gradient -- have to check the math,\n",
    "            # bit this should do the matching correctly\n",
    "            r_vec = r_vec - learning_rate * dL_dr_vec\n",
    "            \n",
    "            if i%20==0:\n",
    "                print('Epoch {}'.format(i))\n",
    "                print('Reward vector: {}'.format(r_vec))\n",
    "                # print('Policy: {}'.format(policy))\n",
    "                # print('Last-step D: {} \\n'.format(D))\n",
    "\n",
    "    return r_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_grid(env,\n",
    "                 horizon=22, #number of timesteps we assume the expert has been acting previously\n",
    "                 temperature_irl=1,\n",
    "                 learning_rate=.1,\n",
    "                 epochs = 500):\n",
    "\n",
    "    print('Number of states: ', env.deterministic_T.shape[0])\n",
    "    print('Initial state:')\n",
    "    print_state(env.init_state)\n",
    "\n",
    "    p_0=np.zeros(env.nS)\n",
    "    p_0[env.state_num[state_to_str(env.init_state)]] = 1\n",
    "    \n",
    "    current_state = np.copy(p_0)\n",
    "    \n",
    "    r_vec = OM_method(env, current_state, p_0, horizon, temperature_irl, epochs, learning_rate)\n",
    "    print('Final reward weights: ', r_vec)\n",
    "    return r_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states:  768\n",
      "Initial state:\n",
      "|\u001b[0;35;85m█\u001b[0m\u001b[0;32;85m█\u001b[0m|  |  |\n",
      "|\u001b[0;33;85m█\u001b[0m |\u001b[0m↑\u001b[0m |\u001b[0;33;85m█\u001b[0m |\n",
      "|––|––|––|\n",
      "|  |  |  |\n",
      "|  |  |  |\n",
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969  0.00865408 -0.02301539]\n",
      "Epoch 0\n",
      "Reward vector: [ 0.01126047 -0.00956236 -0.00529616 -0.01076787  0.03454158 -0.02203465]\n",
      "Epoch 20\n",
      "Reward vector: [-0.00141373 -0.01893179 -0.00533257 -0.01086848  0.14138968 -0.01954165]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-672a355c3662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv2x3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVasesGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVasesEnvSpec2x3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVasesEnvState2x3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mexperiment_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv2x3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-03dc156200b0>\u001b[0m in \u001b[0;36mexperiment_grid\u001b[1;34m(env, horizon, temperature_irl, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mr_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOM_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature_irl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final reward weights: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6e5528ab6ceb>\u001b[0m in \u001b[0;36mOM_method\u001b[1;34m(mdp, current_state, p_0, horizon, temperature, epochs, learning_rate, r_vec)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvi_boltzmann_deterministic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_matrix\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mr_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_D_last_step_discrete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mdL_dr_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-49974b7e88bb>\u001b[0m in \u001b[0;36mcompute_D_last_step_discrete\u001b[1;34m(mdp, policy, p_0, T, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mD_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mD_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env-tf\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \"\"\"\n\u001b[1;32m-> 1497\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[1;31m# Basic operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "env2x3 = VasesGrid(VasesEnvSpec2x3(), VasesEnvState2x3())\n",
    "experiment_grid(env2x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "env2x3_broken = VasesGrid(VasesEnvSpec2x3Broken(), VasesEnvState2x3Broken())\n",
    "experiment_grid(env2x3_broken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
