{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import envs.mdps as mdps\n",
    "from test import get_r_prior\n",
    "from principled_frame_cond_features import om_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_wrapper(env = mdps.MDP_toy_irreversibility(),\n",
    "                        uniform_prior=False,\n",
    "                        std=.5,\n",
    "                        horizon=100,\n",
    "                        temperature=1,\n",
    "                        epochs=100,\n",
    "                        learning_rate=.1,\n",
    "                        prior = \"gaussian\",\n",
    "                        s_current = 2,\n",
    "                        seed=1,\n",
    "                        p_0=None):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    if p_0 is None:\n",
    "        if not uniform_prior:\n",
    "            p_0=np.zeros(env.nS)\n",
    "            p_0[env.init_state] = 1\n",
    "        else:\n",
    "            p_0=np.ones(env.nS) / env.nS\n",
    "\n",
    "    reward_center = np.zeros(env.nS)\n",
    "    r_prior = get_r_prior(prior, reward_center, std)\n",
    "    r_inferred = om_method(env, s_current, p_0, horizon, temperature, epochs, learning_rate, r_prior)\n",
    "    print(f\"Inferred reward vec:   {r_inferred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.9398  3.2048  5.1058 -9.2538]\n",
      "grad error: 3.815181842446551\n",
      "Epoch 1; Reward vector: [ 0.5726  2.1861  5.2916 -8.0523]\n",
      "grad error: 33.52872081959903\n",
      "Epoch 2; Reward vector: [ 0.3519  1.4214  5.5568 -7.3314]\n",
      "grad error: 34.521557731184984\n",
      "Epoch 3; Reward vector: [ 0.2195  0.9054  5.7732 -6.8988]\n",
      "grad error: 34.92105851005251\n",
      "Epoch 4; Reward vector: [ 0.14    0.5776  5.9213 -6.6393]\n",
      "grad error: 35.05151219223976\n",
      "Epoch 5; Reward vector: [ 0.0923  0.3743  6.0167 -6.4836]\n",
      "grad error: 35.099184695723395\n",
      "Epoch 6; Reward vector: [ 0.0637  0.2495  6.0768 -6.3901]\n",
      "grad error: 35.119539101353\n",
      "Epoch 7; Reward vector: [ 0.0466  0.1732  6.1142 -6.3341]\n",
      "grad error: 35.12950175027174\n",
      "Epoch 8; Reward vector: [ 0.0363  0.1267  6.1374 -6.3005]\n",
      "grad error: 35.13490293783898\n",
      "Epoch 9; Reward vector: [ 0.0301  0.0984  6.1517 -6.2803]\n",
      "grad error: 35.1378155239993\n",
      "Epoch 10; Reward vector: [ 0.0264  0.0812  6.1605 -6.2682]\n",
      "grad error: 35.139569968947505\n",
      "Epoch 11; Reward vector: [ 0.0242  0.0707  6.166  -6.2609]\n",
      "grad error: 35.14060087767585\n",
      "Epoch 12; Reward vector: [ 0.0228  0.0644  6.1693 -6.2565]\n",
      "grad error: 35.14105386227879\n",
      "Epoch 13; Reward vector: [ 0.022   0.0605  6.1714 -6.2539]\n",
      "grad error: 35.14142706793461\n",
      "Epoch 14; Reward vector: [ 0.0216  0.0581  6.1727 -6.2524]\n",
      "grad error: 35.14175835148123\n",
      "Epoch 15; Reward vector: [ 0.0213  0.0567  6.1734 -6.2514]\n",
      "grad error: 35.141906211084795\n",
      "Epoch 16; Reward vector: [ 0.0211  0.0558  6.1739 -6.2508]\n",
      "grad error: 35.14195892246839\n",
      "Epoch 17; Reward vector: [ 0.021   0.0553  6.1742 -6.2505]\n",
      "grad error: 35.14213194381258\n",
      "Epoch 18; Reward vector: [ 0.0209  0.055   6.1744 -6.2503]\n",
      "grad error: 35.142189283928076\n",
      "Epoch 19; Reward vector: [ 0.0209  0.0548  6.1745 -6.2502]\n",
      "grad error: 35.142044788616836\n",
      "Epoch 20; Reward vector: [ 0.0209  0.0547  6.1746 -6.2501]\n",
      "grad error: 35.14201360819309\n",
      "Epoch 21; Reward vector: [ 0.0209  0.0546  6.1746 -6.2501]\n",
      "grad error: 35.142231668544\n",
      "\n",
      "Max grad error: 35.142231668544\n",
      "Median grad error: 35.140085423311675\n",
      "Inferred reward vec:   [ 0.02085289  0.0546079   6.17460504 -6.2500659 ]\n"
     ]
    }
   ],
   "source": [
    "experiment_wrapper(uniform_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.9687  3.2569  5.1146 -9.3438]\n",
      "grad error: 6.882284951474643e-07\n",
      "Epoch 1; Reward vector: [ 0.581   1.9432  3.0799 -5.6063]\n",
      "grad error: 0.00021700124606429994\n",
      "Epoch 2; Reward vector: [ 0.347   1.148   1.8675 -3.3638]\n",
      "grad error: 0.00019120908100317643\n",
      "Epoch 3; Reward vector: [ 0.2027  0.6651  1.1497 -2.0183]\n",
      "grad error: 6.560228653208936e-05\n",
      "Epoch 4; Reward vector: [ 0.1105  0.3711  0.7291 -1.2112]\n",
      "grad error: 1.1858054971145693e-05\n",
      "Epoch 5; Reward vector: [ 0.0494  0.1921  0.4864 -0.7282]\n",
      "grad error: 1.1426253552137016e-05\n",
      "Epoch 6; Reward vector: [ 0.0073  0.0841  0.3514 -0.443 ]\n",
      "grad error: 1.9332596368774097e-05\n",
      "Epoch 7; Reward vector: [-0.0231  0.0218  0.2864 -0.2851]\n",
      "grad error: 6.362069890345957e-06\n",
      "Epoch 8; Reward vector: [-0.0457 -0.0076  0.2738 -0.2206]\n",
      "grad error: 1.4756136889697848e-06\n",
      "Epoch 9; Reward vector: [-0.0608 -0.0169  0.2896 -0.212 ]\n",
      "grad error: 1.6457735568328335e-06\n",
      "Epoch 10; Reward vector: [-0.0691 -0.0228  0.2979 -0.2059]\n",
      "grad error: 1.1154379732145724e-06\n",
      "Epoch 11; Reward vector: [-0.0738 -0.0263  0.3029 -0.2028]\n",
      "grad error: 6.531605015632087e-07\n",
      "Epoch 12; Reward vector: [-0.0764 -0.0284  0.3057 -0.2009]\n",
      "grad error: 5.413884474982915e-07\n",
      "Epoch 13; Reward vector: [-0.0779 -0.0297  0.3074 -0.1998]\n",
      "grad error: 6.759770866471661e-07\n",
      "Epoch 14; Reward vector: [-0.0787 -0.0304  0.3083 -0.1992]\n",
      "grad error: 1.190220157447126e-06\n",
      "Epoch 15; Reward vector: [-0.0791 -0.0309  0.3089 -0.1989]\n",
      "grad error: 5.562498193382315e-07\n",
      "Epoch 16; Reward vector: [-0.0794 -0.0312  0.3092 -0.1987]\n",
      "grad error: 9.42909216686085e-07\n",
      "Epoch 17; Reward vector: [-0.0795 -0.0313  0.3094 -0.1985]\n",
      "grad error: 7.346680564861633e-07\n",
      "Epoch 18; Reward vector: [-0.0796 -0.0314  0.3095 -0.1985]\n",
      "grad error: 4.225982167182703e-07\n",
      "Epoch 19; Reward vector: [-0.0796 -0.0315  0.3096 -0.1984]\n",
      "grad error: 8.017826920004906e-07\n",
      "Epoch 20; Reward vector: [-0.0797 -0.0315  0.3096 -0.1984]\n",
      "grad error: 6.737476135111824e-07\n",
      "\n",
      "Max grad error: 0.00021700124606429994\n",
      "Median grad error: 1.1154379732145724e-06\n",
      "Inferred reward vec:   [-0.07965214 -0.03154433  0.30961036 -0.19841402]\n"
     ]
    }
   ],
   "source": [
    "experiment_wrapper(uniform_prior=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.8872  3.1149  4.9973 -9.003 ]\n",
      "grad error: 0.9107723874628921\n",
      "Epoch 1; Reward vector: [ 0.5322  1.8582  3.0093 -5.4018]\n",
      "grad error: 3.012360903757713e-05\n",
      "Epoch 2; Reward vector: [ 0.3176  1.0971  1.825  -3.2411]\n",
      "grad error: 3.2054266060276466e-05\n",
      "Epoch 3; Reward vector: [ 0.185   0.6346  1.1242 -1.9447]\n",
      "grad error: 5.425655470493936e-05\n",
      "Epoch 4; Reward vector: [ 0.0998  0.3528  0.7139 -1.1671]\n",
      "grad error: 5.123187727374348e-05\n",
      "Epoch 5; Reward vector: [ 0.0429  0.1812  0.4776 -0.7019]\n",
      "grad error: 8.984096551576098e-06\n",
      "Epoch 6; Reward vector: [ 0.0032  0.0776  0.3467 -0.4277]\n",
      "grad error: 1.2832224334944767e-05\n",
      "Epoch 7; Reward vector: [-0.0259  0.0183  0.2848 -0.2773]\n",
      "grad error: 8.457421388258743e-06\n",
      "Epoch 8; Reward vector: [-0.0475 -0.009   0.275  -0.2185]\n",
      "grad error: 6.791966562054949e-07\n",
      "Epoch 9; Reward vector: [-0.0618 -0.0175  0.2909 -0.2115]\n",
      "grad error: 7.742961639748335e-07\n",
      "Epoch 10; Reward vector: [-0.0697 -0.0233  0.2984 -0.2055]\n",
      "grad error: 1.3206500369508537e-06\n",
      "Epoch 11; Reward vector: [-0.0741 -0.0265  0.3033 -0.2026]\n",
      "grad error: 1.730641038901663e-06\n",
      "Epoch 12; Reward vector: [-0.0766 -0.0286  0.3059 -0.2007]\n",
      "grad error: 7.484401750064719e-07\n",
      "Epoch 13; Reward vector: [-0.078  -0.0298  0.3075 -0.1997]\n",
      "grad error: 1.545580250318157e-06\n",
      "Epoch 14; Reward vector: [-0.0787 -0.0305  0.3084 -0.1992]\n",
      "grad error: 1.0442482301435356e-06\n",
      "Epoch 15; Reward vector: [-0.0792 -0.0309  0.3089 -0.1988]\n",
      "grad error: 9.358390934450308e-07\n",
      "Epoch 16; Reward vector: [-0.0794 -0.0312  0.3092 -0.1986]\n",
      "grad error: 6.689218114745395e-07\n",
      "Epoch 17; Reward vector: [-0.0795 -0.0314  0.3094 -0.1985]\n",
      "grad error: 6.527830942567328e-07\n",
      "Epoch 18; Reward vector: [-0.0796 -0.0315  0.3095 -0.1985]\n",
      "grad error: 1.6110213006581813e-06\n",
      "Epoch 19; Reward vector: [-0.0796 -0.0315  0.3096 -0.1984]\n",
      "grad error: 9.323269073978997e-07\n",
      "\n",
      "Max grad error: 0.9107723874628921\n",
      "Median grad error: 1.5783007754881692e-06\n",
      "Inferred reward vec:   [-0.0796327  -0.03151199  0.30957742 -0.19843295]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.asarray([.33333333333, .33333333333, .33333333333, 0])\n",
    "experiment_wrapper(p_0=p_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.9123  3.1776  5.0451 -9.1384]\n",
      "grad error: 0.6734296030028841\n",
      "Epoch 1; Reward vector: [ 0.5472  1.8957  3.0381 -5.4831]\n",
      "grad error: 0.00016419692290030655\n",
      "Epoch 2; Reward vector: [ 0.3267  1.1196  1.8423 -3.2898]\n",
      "grad error: 0.00023979443621924425\n",
      "Epoch 3; Reward vector: [ 0.1905  0.6481  1.1346 -1.9739]\n",
      "grad error: 9.458457301419409e-05\n",
      "Epoch 4; Reward vector: [ 0.1032  0.3609  0.7201 -1.1846]\n",
      "grad error: 1.7880680171271426e-05\n",
      "Epoch 5; Reward vector: [ 0.0449  0.186   0.4812 -0.7124]\n",
      "grad error: 1.2191071226598323e-05\n",
      "Epoch 6; Reward vector: [ 0.0045  0.0804  0.3486 -0.4338]\n",
      "grad error: 1.1046175302698592e-05\n",
      "Epoch 7; Reward vector: [-0.025   0.0198  0.2854 -0.2804]\n",
      "grad error: 5.091092908882433e-06\n",
      "Epoch 8; Reward vector: [-0.0469 -0.0084  0.2745 -0.2193]\n",
      "grad error: 5.510656126086785e-07\n",
      "Epoch 9; Reward vector: [-0.0615 -0.0172  0.2904 -0.2117]\n",
      "grad error: 6.986764084011782e-07\n",
      "Epoch 10; Reward vector: [-0.0695 -0.0231  0.2982 -0.2056]\n",
      "grad error: 4.6758809607013115e-07\n",
      "Epoch 11; Reward vector: [-0.074  -0.0264  0.3031 -0.2027]\n",
      "grad error: 5.730162922379292e-07\n",
      "Epoch 12; Reward vector: [-0.0765 -0.0285  0.3058 -0.2008]\n",
      "grad error: 7.021281425222107e-07\n",
      "Epoch 13; Reward vector: [-0.0779 -0.0297  0.3074 -0.1998]\n",
      "grad error: 9.603678429544824e-07\n",
      "Epoch 14; Reward vector: [-0.0787 -0.0305  0.3084 -0.1992]\n",
      "grad error: 1.1683280343338944e-06\n",
      "Epoch 15; Reward vector: [-0.0792 -0.0309  0.3089 -0.1988]\n",
      "grad error: 1.0895622728439754e-06\n",
      "Epoch 16; Reward vector: [-0.0794 -0.0312  0.3092 -0.1986]\n",
      "grad error: 1.308856380001755e-06\n",
      "Epoch 17; Reward vector: [-0.0795 -0.0314  0.3094 -0.1985]\n",
      "grad error: 5.077565001193026e-07\n",
      "Epoch 18; Reward vector: [-0.0796 -0.0315  0.3095 -0.1985]\n",
      "grad error: 1.0700932159648846e-06\n",
      "Epoch 19; Reward vector: [-0.0796 -0.0315  0.3096 -0.1984]\n",
      "grad error: 1.0893749830937334e-06\n",
      "Epoch 20; Reward vector: [-0.0797 -0.0315  0.3096 -0.1984]\n",
      "grad error: 7.159532375869976e-07\n",
      "\n",
      "Max grad error: 0.6734296030028841\n",
      "Median grad error: 1.0895622728439754e-06\n",
      "Inferred reward vec:   [-0.07965325 -0.03154564  0.30961186 -0.1984131 ]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.asarray([.5, .5, 0, 0])\n",
    "experiment_wrapper(p_0=p_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.8914  3.1258  5.0172 -9.0379]\n",
      "grad error: 1.3743489089107415\n",
      "Epoch 1; Reward vector: [ 0.5347  1.8648  3.0212 -5.4227]\n",
      "grad error: 0.00012278701623502964\n",
      "Epoch 2; Reward vector: [ 0.3192  1.1011  1.8321 -3.2536]\n",
      "grad error: 3.0462086403373782e-05\n",
      "Epoch 3; Reward vector: [ 0.186   0.6371  1.1284 -1.9522]\n",
      "grad error: 5.77977971420713e-05\n",
      "Epoch 4; Reward vector: [ 0.1005  0.3543  0.7163 -1.1716]\n",
      "grad error: 9.372295094901771e-06\n",
      "Epoch 5; Reward vector: [ 0.0433  0.1821  0.479  -0.7046]\n",
      "grad error: 1.3226847051502328e-05\n",
      "Epoch 6; Reward vector: [ 0.0035  0.0781  0.3474 -0.4292]\n",
      "grad error: 1.2793144286088109e-05\n",
      "Epoch 7; Reward vector: [-0.0257  0.0185  0.2851 -0.2781]\n",
      "grad error: 4.946408993186411e-06\n",
      "Epoch 8; Reward vector: [-0.0474 -0.0089  0.2749 -0.2187]\n",
      "grad error: 1.7623241833522412e-06\n",
      "Epoch 9; Reward vector: [-0.0617 -0.0175  0.2908 -0.2116]\n",
      "grad error: 1.3119401752966462e-06\n",
      "Epoch 10; Reward vector: [-0.0697 -0.0232  0.2984 -0.2055]\n",
      "grad error: 1.2565504614668578e-06\n",
      "Epoch 11; Reward vector: [-0.0741 -0.0265  0.3032 -0.2026]\n",
      "grad error: 1.1210676819721028e-06\n",
      "Epoch 12; Reward vector: [-0.0766 -0.0286  0.3059 -0.2008]\n",
      "grad error: 8.640198607301457e-07\n",
      "Epoch 13; Reward vector: [-0.078  -0.0298  0.3075 -0.1998]\n",
      "grad error: 5.347532753091748e-07\n",
      "Epoch 14; Reward vector: [-0.0787 -0.0305  0.3084 -0.1992]\n",
      "grad error: 7.419287679065632e-07\n",
      "Epoch 15; Reward vector: [-0.0792 -0.0309  0.3089 -0.1988]\n",
      "grad error: 9.294745020854795e-07\n",
      "Epoch 16; Reward vector: [-0.0794 -0.0312  0.3092 -0.1986]\n",
      "grad error: 8.754098893646649e-07\n",
      "Epoch 17; Reward vector: [-0.0795 -0.0314  0.3094 -0.1985]\n",
      "grad error: 1.221859401885741e-06\n",
      "Epoch 18; Reward vector: [-0.0796 -0.0315  0.3095 -0.1985]\n",
      "grad error: 8.025896076006559e-07\n",
      "Epoch 19; Reward vector: [-0.0796 -0.0315  0.3096 -0.1984]\n",
      "grad error: 5.426262059383382e-07\n",
      "\n",
      "Max grad error: 1.3743489089107415\n",
      "Median grad error: 1.284245318381752e-06\n",
      "Inferred reward vec:   [-0.07963243 -0.03151174  0.30957711 -0.19843315]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.asarray([.5, 0, .5, 0])\n",
    "experiment_wrapper(p_0=p_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial reward vector: [ 0.01624345 -0.00611756 -0.00528172 -0.01072969]\n",
      "Epoch 0; Reward vector: [ 0.8607  3.0327  4.8962 -8.7932]\n",
      "grad error: 0.38409014700139477\n",
      "Epoch 1; Reward vector: [ 0.5162  1.8088  2.9488 -5.2759]\n",
      "grad error: 0.0002446499155807683\n",
      "Epoch 2; Reward vector: [ 0.308   1.0673  1.789  -3.1656]\n",
      "grad error: 9.221897102951086e-05\n",
      "Epoch 3; Reward vector: [ 0.1791  0.6166  1.1029 -1.8994]\n",
      "grad error: 0.00011696691328665293\n",
      "Epoch 4; Reward vector: [ 0.0961  0.3419  0.7015 -1.1399]\n",
      "grad error: 4.4755173046187223e-05\n",
      "Epoch 5; Reward vector: [ 0.0404  0.1746  0.4705 -0.6857]\n",
      "grad error: 2.294626082537668e-05\n",
      "Epoch 6; Reward vector: [ 0.0015  0.0737  0.343  -0.4183]\n",
      "grad error: 1.4840530775711508e-05\n",
      "Epoch 7; Reward vector: [-0.0271  0.0162  0.2836 -0.2727]\n",
      "grad error: 5.952674833399607e-06\n",
      "Epoch 8; Reward vector: [-0.0484 -0.0098  0.2756 -0.2175]\n",
      "grad error: 1.1146833058188303e-06\n",
      "Epoch 9; Reward vector: [-0.0623 -0.0179  0.2915 -0.2113]\n",
      "grad error: 1.2664400411587513e-06\n",
      "Epoch 10; Reward vector: [-0.07   -0.0235  0.2987 -0.2052]\n",
      "grad error: 8.454191734999391e-07\n",
      "Epoch 11; Reward vector: [-0.0743 -0.0267  0.3035 -0.2025]\n",
      "grad error: 1.275260363974127e-06\n",
      "Epoch 12; Reward vector: [-0.0767 -0.0287  0.306  -0.2007]\n",
      "grad error: 1.914435104675513e-06\n",
      "Epoch 13; Reward vector: [-0.078  -0.0298  0.3076 -0.1997]\n",
      "grad error: 3.740692738889076e-07\n",
      "Epoch 14; Reward vector: [-0.0788 -0.0305  0.3084 -0.1991]\n",
      "grad error: 8.106333713351599e-07\n",
      "Epoch 15; Reward vector: [-0.0792 -0.031   0.3089 -0.1988]\n",
      "grad error: 2.1059544643893683e-07\n",
      "Epoch 16; Reward vector: [-0.0794 -0.0312  0.3092 -0.1986]\n",
      "grad error: 4.580980142669279e-07\n",
      "Epoch 17; Reward vector: [-0.0795 -0.0314  0.3094 -0.1985]\n",
      "grad error: 7.301758084982802e-07\n",
      "Epoch 18; Reward vector: [-0.0796 -0.0315  0.3095 -0.1985]\n",
      "grad error: 2.6752529176687624e-07\n",
      "Epoch 19; Reward vector: [-0.0796 -0.0315  0.3096 -0.1984]\n",
      "grad error: 8.661845258648474e-07\n",
      "\n",
      "Max grad error: 0.38409014700139477\n",
      "Median grad error: 1.2708502025664393e-06\n",
      "Inferred reward vec:   [-0.07963392 -0.03151455  0.30957986 -0.19843161]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.asarray([0.1, 0, .9, 0])\n",
    "experiment_wrapper(p_0=p_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
